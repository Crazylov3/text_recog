vocab: 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~ '

device: cuda:0
trainer:
  batch_size: 8
  print_every: 200
  valid_every: 2000
  iters: 200000
  # where to save our model for prediction
  export: /content/drive/MyDrive/real_text_recog_out/weights/transformerocr.pth
  checkpoint_best: /content/drive/MyDrive/real_text_recog_out/checkpoint/transformerocr_checkpoint_best.pth
  checkpoint_last: /content/drive/MyDrive/real_text_recog_out/checkpoint/transformerocr_checkpoint_last.pth
  log: /content/drive/MyDrive/real_text_recog_out/train.log
  tensorboard_log: /content/drive/MyDrive/real_text_recog_out
  # null to disable compuate accuracy, or change to number of sample to enable validiation while training
  metrics: null

dataset:
  # name of your dataset
  name: ocr_data
  # path to annotation and image
  data_root: /content/real_text_recog
  train_annotation: train.txt
  valid_annotation: test.txt
  gen_data_path: /content/drive/MyDrive/real_text_recog_out
  # resize image to 32 height, larger height will increase accuracy
  image_height: 32
  image_min_width: 32
  image_max_width: 512

dataloader:
  num_workers: 3
  pin_memory: True

aug:
  image_aug: true
  masked_language_model: true

predictor:
  # disable or enable beamsearch while prediction, use beamsearch will be slower
  beamsearch: False

quiet: False

pretrain:
  id_or_url: 1nTKlEog9YFK74kPyX0qLwCWi60_YHHk4
  md5: efcabaa6d3adfca8e52bda2fd7d2ee04
  cached: /tmp/tranformerorc.pth

# url or local path
weights: https://drive.google.com/uc?id=1nTKlEog9YFK74kPyX0qLwCWi60_YHHk4

backbone: vgg19_bn
cnn:
  # pooling stride size
  ss:
    - [ 2, 2 ]
    - [ 2, 2 ]
    - [ 2, 1 ]
    - [ 2, 1 ]
    - [ 1, 1 ]
  # pooling kernel size
  ks:
    - [ 2, 2 ]
    - [ 2, 2 ]
    - [ 2, 1 ]
    - [ 2, 1 ]
    - [ 1, 1 ]
  # dim of ouput feature map
  hidden: 256
seq_modeling: seq2seq
transformer:
  encoder_hidden: 256
  decoder_hidden: 256
  img_ch16annel: 256
  decoder_embedded: 256
  dropout: 0.1

optimizer:
  max_lr: 0.00005
  pct_start: 0.

lr:
  name: CosineAnnealingLR
  params:
    T_max: 100000
    eta_min: 0.000001